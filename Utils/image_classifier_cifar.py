# -*- coding: utf-8 -*-
"""
Created on Mon Mar  1 19:07:00 2021

@author: Saeid
"""

"""Mnist_fashion_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at

    https://colab.research.google.com/drive/1EeYH6GEH6tTDHPsVZ8kbWLbRKZZXmXml
"""

"""In this class, some pre- and post-processing functions for image (Mnist) classification are represented.
   Different functions are developed in order to plot and present the training and test datasets.
   Moreover, some functions are presented to show the convergence procedure, wrong predictions and
   confusion matrix.
"""

# Importing required libraries
import matplotlib.pyplot as plt
import numpy as np
import itertools
from sklearn.metrics import confusion_matrix

class CIFAR10:
    
    def __init__(self,X_train, y_train, X_test, y_test):
        
        self.X_train = X_train
        self.y_train = y_train.reshape(-1)
        self.X_test = X_test
        self.y_test = y_test.reshape(-1)
        self.num_classes = len(set(self.y_test)) 
        
        # The size of input data
        self.width = X_train.shape[1]
        self.height = X_train.shape[2]
        self.channel = X_train.shape[3]
        
        # Label_map for defining the digit related to each class
        self.label_map = {0: 	"airplane",
                          1: 	"automobile",
                          2: 	"bird",
                          3: 	"cat",
                          4: 	"deer",
                          5: 	"dog",
                          6: 	"frog",
                          7: 	"horse",
                          8: 	"ship",
                          9: 	"truck"}
    
    # In this function, the information of the mnist dataset is revealed and an example of each class is plotted.
    def data_desciption(self):
        
        print("The shape of X_train is : {}".format(self.X_train.shape))
        print("The shape of y_train is : {}".format(self.y_train.shape))
        print("The shape of X_test is : {}".format(self.X_test.shape))
        print("The shape of y_test is : {}".format(self.y_test.shape)) 
        print("The number of classes is {}".format(self.num_classes))
        
        # for i in range(self.num_classes):
        #     j = np.where(self.y_train == i)[0][0]
        #     print(self.label_map[self.y_train[j]])
        
        fig, axes = plt.subplots(nrows = 1, ncols = 10, figsize = [30,4])
        fig.suptitle("Example of all classes", fontsize=16)
        for i, ax in enumerate(axes):
            j = np.where(self.y_train == i)[0][1]
            ax.imshow(self.X_train[j].reshape(self.width, self.height, self.channel))
            ax.set_xticklabels([])
            ax.set_yticklabels([])
            ax.set_xlabel(self.label_map[self.y_train[j]], fontsize = 14)
        
        return (self.label_map, self.num_classes)
    
    # In this function training and test input data are flattened
    def flat(self):
        
        num_obs_train = self.X_train.shape[0]
        num_obs_test = self.X_test.shape[0]
        X_train_f = self.X_train.reshape(num_obs_train, -1)
        X_test_f = self.X_test.reshape(num_obs_test, -1)
        
        return X_train_f, X_test_f
        
    # In this function, the loss and accuracy of the model is plotted.
    def loss_accuracy(self, model_dict, epochs):
        
        loss = model_dict.history["loss"]
        val_loss = model_dict.history["val_loss"]
        acc = model_dict.history["accuracy"]
        val_acc = model_dict.history["val_accuracy"]
        
        fig, [ax1,ax2] = plt.subplots(nrows = 1, ncols = 2,figsize = [15,8])
        fig.suptitle("Loss and Accuracy convergence", fontsize=16)
        ax1.plot(np.arange(epochs),loss, label = "loss")
        ax1.plot(np.arange(epochs),val_loss, label = "val_loss")
        ax1.set_xlabel("Epochs")
        ax1.set_ylabel("loss")
        ax1.legend()
        ax1.set_xticks(np.arange(epochs))
        ax1.set_xticklabels(np.arange(epochs))
        
        ax2.plot(np.arange(epochs),acc, label = "accuracy")
        ax2.plot(np.arange(epochs),val_acc, label = "val_accuracy")
        ax2.set_xlabel("Epochs")
        ax2.set_ylabel("accuracy")
        ax2.set_xticks(np.arange(epochs))
        ax2.set_xticklabels(np.arange(epochs))
        ax2.legend()
    
    # In this function, the confusion matrix which represents the correct and wrong predictions via a heatmap is presented.
    def confusion_matrixx(self, y_pred, fontsize = 14,thresh = 50,cmap = plt.cm.Blues):
        
        cm = confusion_matrix(y_pred = y_pred, y_true = self.y_test)
        plt.figure(figsize = [10,10])
        plt.imshow(cm, cmap = cmap)
        plt.xlabel("Predicted class", fontsize = fontsize)
        plt.ylabel("True class", fontsize = fontsize)
        plt.title("Confusion Matrix")
        plt.xticks(np.arange(self.num_classes),list(self.label_map.values()), fontsize = fontsize,rotation = 45)
        plt.yticks(np.arange(self.num_classes),list(self.label_map.values()), fontsize = fontsize)
        plt.colorbar()
          
        for i, j  in itertools.product(range(self.num_classes), range(self.num_classes)):
            plt.text(j, i, cm[i,j],
                     c = "red" if cm[i,j] > thresh else "black",
                     horizontalalignment = "center", fontsize = fontsize)
    
    # In this function, a number of wrong predictions along with the true class are randomly chosen and plotted.
    def wrong_pred(self, y_pred):
        
        Wrong_pred_idx = np.where(self.y_test != y_pred)[0]
        random_wrong_pred = np.random.choice(Wrong_pred_idx, size = 20)
        fig, axes = plt.subplots(nrows = 4, ncols = 5, figsize = [15,10])
        fig.suptitle("Random Wrong Predictions", fontsize=16)
        plt.subplots_adjust(left = None, bottom = None, right = None, top = None, wspace = 1, hspace = 1)
        for i, ax in enumerate(axes.reshape(-1)):
            j = random_wrong_pred[i]
            ax.imshow(self.X_test[j].reshape(self.width, self.height, self.channel))
            ax.set_xlabel("True : {}\nPred : {}".format(self.label_map[self.y_test[j]], self.label_map[y_pred[j]]), fontsize = 12)
            ax.set_xticklabels([])
            ax.set_yticklabels([])
         